"""
ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ
ì‹œì¥ ë° ê°œë³„ ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘

ì§€ì› ì†ŒìŠ¤:
- NewsAPI (API í‚¤ í•„ìš”)
- Alpha Vantage News Sentiment (API í‚¤ í•„ìš”, ê¸ˆìœµ íŠ¹í™”)
- Finnhub (API í‚¤ í•„ìš”, ê¸ˆìœµ íŠ¹í™”)
- Yahoo Finance (ë¬´ë£Œ)
"""
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import os
from bs4 import BeautifulSoup
import yfinance as yf


class NewsCollector:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ í´ë˜ìŠ¤ (ë‹¤ì¤‘ ì†ŒìŠ¤ ì§€ì›)"""
    
    def __init__(self):
        self.news_api_key = os.getenv("NEWS_API_KEY")
        self.alpha_vantage_key = os.getenv("ALPHA_VANTAGE_API_KEY")
        self.finnhub_key = os.getenv("FINNHUB_API_KEY")  # ì„ íƒì 
        self.marketaux_key = os.getenv("MARKETAUX_API_KEY")  # ì„ íƒì  (100/day ë¬´ë£Œ)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def get_market_news(self, days: int = 7, max_articles: int = 20) -> List[Dict]:
        """ì‹œì¥ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë‹¤ì¤‘ ì†ŒìŠ¤)"""
        news = []
        
        # 1. NewsAPI ì‚¬ìš© (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        if self.news_api_key:
            news.extend(self._get_newsapi_news(
                query="stock market OR S&P 500 OR Federal Reserve OR economy",
                days=days,
                max_articles=max_articles // 3
            ))
        
        # 2. Alpha Vantage News (ê¸ˆìœµ íŠ¹í™”, ê°ì„± ë¶„ì„ í¬í•¨)
        if self.alpha_vantage_key:
            av_news = self._get_alphavantage_news(
                topics="economy,finance,financial_markets",
                max_articles=max_articles // 3
            )
            news.extend(av_news)
        
        # 3. Finnhub (ê¸ˆìœµ íŠ¹í™”)
        if self.finnhub_key:
            fh_news = self._get_finnhub_news(
                category="general",
                max_articles=max_articles // 4
            )
            news.extend(fh_news)
        
        # 4. Marketaux (ê¸ˆìœµ íŠ¹í™”, ê°ì„± ë¶„ì„ í¬í•¨)
        if self.marketaux_key:
            mx_news = self._get_marketaux_news(
                topics="market,stock",
                max_articles=max_articles // 4
            )
            news.extend(mx_news)
        
        # 5. Yahoo Finance ë‰´ìŠ¤ (ë¬´ë£Œ)
        news.extend(self._get_yahoo_market_news(max_articles=max_articles // 4))
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        seen_titles = set()
        unique_news = []
        for article in news:
            title_key = article.get('title', '')[:50].lower()
            if title_key not in seen_titles and article.get('title'):
                seen_titles.add(title_key)
                unique_news.append(article)
        
        # ë‚ ì§œìˆœ ì •ë ¬
        unique_news.sort(key=lambda x: x.get('published', ''), reverse=True)
        
        return unique_news[:max_articles]
    
    def get_stock_news(self, ticker: str, max_articles: int = 10) -> List[Dict]:
        """ê°œë³„ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ (ë‹¤ì¤‘ ì†ŒìŠ¤)"""
        news = []
        
        # Yahoo Financeì—ì„œ ì¢…ëª© ë‰´ìŠ¤
        try:
            stock = yf.Ticker(ticker)
            yf_news = stock.news
            
            for article in yf_news[:max_articles // 2]:
                news.append({
                    'title': article.get('title', ''),
                    'summary': article.get('summary', ''),
                    'source': article.get('publisher', 'Yahoo Finance'),
                    'url': article.get('link', ''),
                    'published': datetime.fromtimestamp(
                        article.get('providerPublishTime', 0)
                    ).isoformat() if article.get('providerPublishTime') else '',
                    'ticker': ticker,
                    'type': 'stock_news'
                })
        except Exception as e:
            print(f"Yahoo Finance ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ ({ticker}): {e}")
        
        # Alpha Vantage (ê°ì„± ë¶„ì„ í¬í•¨)
        if self.alpha_vantage_key:
            av_news = self._get_alphavantage_news(
                tickers=ticker,
                max_articles=max_articles // 3
            )
            for article in av_news:
                article['ticker'] = ticker
            news.extend(av_news)
        
        # Finnhub 
        if self.finnhub_key:
            fh_news = self._get_finnhub_news(
                ticker=ticker,
                max_articles=max_articles // 3
            )
            news.extend(fh_news)
        
        # NewsAPI ì¶”ê°€ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        if self.news_api_key:
            try:
                stock = yf.Ticker(ticker)
                company_name = stock.info.get('shortName', ticker)
                
                api_news = self._get_newsapi_news(
                    query=f"{company_name} OR {ticker}",
                    days=7,
                    max_articles=max_articles // 3
                )
                for article in api_news:
                    article['ticker'] = ticker
                    article['type'] = 'stock_news'
                news.extend(api_news)
            except:
                pass
        
        # ì¤‘ë³µ ì œê±°
        seen_titles = set()
        unique_news = []
        for article in news:
            title_key = article.get('title', '')[:50].lower()
            if title_key not in seen_titles and article.get('title'):
                seen_titles.add(title_key)
                unique_news.append(article)
        
        return unique_news[:max_articles]
    
    def get_economic_news(self, days: int = 7, max_articles: int = 15) -> List[Dict]:
        """ê²½ì œ ì§€í‘œ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        keywords = [
            "GDP growth", "inflation rate", "unemployment", 
            "Federal Reserve", "interest rate", "CPI",
            "economic outlook", "recession", "recovery"
        ]
        
        news = []
        
        if self.news_api_key:
            query = " OR ".join(keywords[:5])  # API ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ
            news.extend(self._get_newsapi_news(
                query=query,
                days=days,
                max_articles=max_articles
            ))
        
        # Yahoo Finance ê²½ì œ ë‰´ìŠ¤
        news.extend(self._get_yahoo_economic_news(max_articles=max_articles // 2))
        
        for article in news:
            article['type'] = 'economic_news'
        
        return news[:max_articles]
    
    def _get_newsapi_news(self, query: str, days: int = 7, max_articles: int = 20) -> List[Dict]:
        """NewsAPIì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
        if not self.news_api_key:
            return []
        
        news = []
        from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
        
        try:
            url = "https://newsapi.org/v2/everything"
            params = {
                'q': query,
                'from': from_date,
                'sortBy': 'relevancy',
                'language': 'en',
                'pageSize': max_articles,
                'apiKey': self.news_api_key
            }
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                for article in data.get('articles', []):
                    news.append({
                        'title': article.get('title', ''),
                        'summary': article.get('description', ''),
                        'source': article.get('source', {}).get('name', 'Unknown'),
                        'url': article.get('url', ''),
                        'published': article.get('publishedAt', ''),
                        'type': 'market_news'
                    })
        except Exception as e:
            print(f"NewsAPI ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news
    
    def _get_alphavantage_news(self, tickers: str = None, topics: str = None, 
                                max_articles: int = 20) -> List[Dict]:
        """
        Alpha Vantage News Sentiment APIì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        - ê¸ˆìœµ ë‰´ìŠ¤ íŠ¹í™”
        - ê°ì„± ì ìˆ˜ í¬í•¨
        
        Args:
            tickers: í‹°ì»¤ (ì˜ˆ: "AAPL" ë˜ëŠ” "AAPL,MSFT")
            topics: í† í”½ (ì˜ˆ: "technology", "finance", "economy")
        """
        if not self.alpha_vantage_key:
            return []
        
        news = []
        
        try:
            url = "https://www.alphavantage.co/query"
            params = {
                'function': 'NEWS_SENTIMENT',
                'apikey': self.alpha_vantage_key,
                'limit': max_articles,
                'sort': 'LATEST'
            }
            
            if tickers:
                params['tickers'] = tickers
            if topics:
                params['topics'] = topics
            
            response = requests.get(url, params=params, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                
                # API í•œë„ ì´ˆê³¼ ì²´í¬
                if 'Note' in data or 'Information' in data:
                    print(f"âš ï¸ Alpha Vantage API í•œë„: {data.get('Note', data.get('Information', ''))[:100]}")
                    return []
                
                for article in data.get('feed', []):
                    # ê°ì„± ì ìˆ˜ ê³„ì‚° (Alpha VantageëŠ” -1 ~ 1 ìŠ¤ì¼€ì¼)
                    sentiment_score = article.get('overall_sentiment_score', 0)
                    sentiment_label = article.get('overall_sentiment_label', 'Neutral')
                    
                    # í‹°ì»¤ë³„ ê°ì„± ì¶”ì¶œ
                    ticker_sentiments = {}
                    for ts in article.get('ticker_sentiment', []):
                        ticker_sentiments[ts.get('ticker', '')] = {
                            'score': float(ts.get('ticker_sentiment_score', 0)),
                            'label': ts.get('ticker_sentiment_label', 'Neutral'),
                            'relevance': float(ts.get('relevance_score', 0))
                        }
                    
                    news.append({
                        'title': article.get('title', ''),
                        'summary': article.get('summary', ''),
                        'source': article.get('source', 'Unknown'),
                        'url': article.get('url', ''),
                        'published': article.get('time_published', ''),
                        'type': 'alphavantage_news',
                        'sentiment': {
                            'score': sentiment_score,
                            'label': sentiment_label
                        },
                        'ticker_sentiments': ticker_sentiments,
                        'topics': [t.get('topic', '') for t in article.get('topics', [])],
                        'banner_image': article.get('banner_image', '')
                    })
                    
        except Exception as e:
            print(f"Alpha Vantage News ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news
    
    def _get_finnhub_news(self, category: str = "general", 
                          ticker: str = None, max_articles: int = 20) -> List[Dict]:
        """
        Finnhubì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        - ë¬´ë£Œ: 60 ìš”ì²­/ë¶„
        - ê¸ˆìœµ ë‰´ìŠ¤ íŠ¹í™”
        
        Args:
            category: "general", "forex", "crypto", "merger"
            ticker: ê°œë³„ ì¢…ëª© í‹°ì»¤ (ì¢…ëª© ë‰´ìŠ¤ìš©)
        """
        if not self.finnhub_key:
            return []
        
        news = []
        
        try:
            if ticker:
                # ì¢…ëª©ë³„ ë‰´ìŠ¤
                url = "https://finnhub.io/api/v1/company-news"
                from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
                to_date = datetime.now().strftime('%Y-%m-%d')
                params = {
                    'symbol': ticker,
                    'from': from_date,
                    'to': to_date,
                    'token': self.finnhub_key
                }
            else:
                # ì¼ë°˜ ì‹œì¥ ë‰´ìŠ¤
                url = "https://finnhub.io/api/v1/news"
                params = {
                    'category': category,
                    'token': self.finnhub_key
                }
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                for article in data[:max_articles]:
                    news.append({
                        'title': article.get('headline', ''),
                        'summary': article.get('summary', ''),
                        'source': article.get('source', 'Unknown'),
                        'url': article.get('url', ''),
                        'published': datetime.fromtimestamp(
                            article.get('datetime', 0)
                        ).isoformat() if article.get('datetime') else '',
                        'type': 'finnhub_news',
                        'ticker': ticker or article.get('related', ''),
                        'category': article.get('category', category),
                        'image': article.get('image', '')
                    })
                    
        except Exception as e:
            print(f"Finnhub News ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news
    
    def _get_marketaux_news(self, symbols: str = None, topics: str = None,
                            max_articles: int = 20) -> List[Dict]:
        """
        Marketauxì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        - ë¬´ë£Œ: 100 ìš”ì²­/ì¼
        - ê¸ˆìœµ ë‰´ìŠ¤ íŠ¹í™”, ê°ì„± ë¶„ì„ í¬í•¨
        
        Args:
            symbols: í‹°ì»¤ (ì˜ˆ: "AAPL" ë˜ëŠ” "AAPL,MSFT")
            topics: í† í”½ í•„í„° (ì˜ˆ: "earnings", "ipo", "merger")
        """
        if not self.marketaux_key:
            return []
        
        news = []
        
        try:
            url = "https://api.marketaux.com/v1/news/all"
            params = {
                'api_token': self.marketaux_key,
                'language': 'en',
                'limit': max_articles,
                'sort': 'published_desc'
            }
            
            if symbols:
                params['symbols'] = symbols
            if topics:
                params['filter_entities'] = 'true'
                params['topics'] = topics
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                for article in data.get('data', []):
                    # Marketaux ê°ì„± ì •ë³´ ì¶”ì¶œ
                    entities = article.get('entities', [])
                    ticker_sentiments = {}
                    for entity in entities:
                        if entity.get('type') == 'equity':
                            ticker_sentiments[entity.get('symbol', '')] = {
                                'score': entity.get('sentiment_score', 0),
                                'highlights': entity.get('highlights', [])
                            }
                    
                    news.append({
                        'title': article.get('title', ''),
                        'summary': article.get('description', ''),
                        'source': article.get('source', 'Unknown'),
                        'url': article.get('url', ''),
                        'published': article.get('published_at', ''),
                        'type': 'marketaux_news',
                        'ticker_sentiments': ticker_sentiments,
                        'image': article.get('image_url', ''),
                        'relevance_score': article.get('relevance_score', 0)
                    })
            elif response.status_code == 429:
                print("âš ï¸ Marketaux API ì¼ì¼ í•œë„ ì´ˆê³¼")
            else:
                print(f"âš ï¸ Marketaux API ì˜¤ë¥˜: {response.status_code}")
                    
        except Exception as e:
            print(f"Marketaux News ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news
    
    def get_comprehensive_stock_news(self, ticker: str, max_articles: int = 15) -> Dict:
        """
        ê°œë³„ ì¢…ëª©ì— ëŒ€í•œ ì¢…í•© ë‰´ìŠ¤ (ëª¨ë“  ì†ŒìŠ¤ í†µí•©)
        ê°ì„± ë¶„ì„ í¬í•¨
        """
        all_news = []
        source_stats = {}
        
        # 1. Yahoo Finance (ë¬´ë£Œ, í•­ìƒ ì‚¬ìš©)
        yf_news = []
        try:
            stock = yf.Ticker(ticker)
            for article in stock.news[:5]:
                yf_news.append({
                    'title': article.get('title', ''),
                    'summary': article.get('summary', ''),
                    'source': article.get('publisher', 'Yahoo Finance'),
                    'url': article.get('link', ''),
                    'published': datetime.fromtimestamp(
                        article.get('providerPublishTime', 0)
                    ).isoformat() if article.get('providerPublishTime') else '',
                    'type': 'yahoo_finance',
                    'ticker': ticker
                })
            all_news.extend(yf_news)
            source_stats['Yahoo Finance'] = len(yf_news)
        except Exception as e:
            source_stats['Yahoo Finance'] = f"ì‹¤íŒ¨: {e}"
        
        # 2. Alpha Vantage (ê°ì„± ì ìˆ˜ í¬í•¨)
        if self.alpha_vantage_key:
            av_news = self._get_alphavantage_news(tickers=ticker, max_articles=5)
            all_news.extend(av_news)
            source_stats['Alpha Vantage'] = len(av_news)
        
        # 3. Finnhub
        if self.finnhub_key:
            fh_news = self._get_finnhub_news(ticker=ticker, max_articles=4)
            all_news.extend(fh_news)
            source_stats['Finnhub'] = len(fh_news)
        
        # 4. Marketaux (ê°ì„± ë¶„ì„ í¬í•¨)
        if self.marketaux_key:
            mx_news = self._get_marketaux_news(symbols=ticker, max_articles=4)
            all_news.extend(mx_news)
            source_stats['Marketaux'] = len(mx_news)
        
        # 5. NewsAPI
        if self.news_api_key:
            try:
                stock = yf.Ticker(ticker)
                company_name = stock.info.get('shortName', ticker)
                na_news = self._get_newsapi_news(
                    query=f'"{company_name}" OR {ticker}',
                    days=7,
                    max_articles=5
                )
                for article in na_news:
                    article['ticker'] = ticker
                all_news.extend(na_news)
                source_stats['NewsAPI'] = len(na_news)
            except:
                source_stats['NewsAPI'] = 0
        
        # ì¤‘ë³µ ì œê±°
        seen_titles = set()
        unique_news = []
        for article in all_news:
            title_key = article['title'][:50].lower()
            if title_key not in seen_titles and article['title']:
                seen_titles.add(title_key)
                unique_news.append(article)
        
        # ë‚ ì§œìˆœ ì •ë ¬
        unique_news.sort(key=lambda x: x.get('published', ''), reverse=True)
        
        # Alpha Vantage ë‰´ìŠ¤ì—ì„œ ê°ì„± ì ìˆ˜ ì¶”ì¶œ
        av_sentiments = [n.get('sentiment', {}).get('score', 0) 
                        for n in unique_news if n.get('type') == 'alphavantage_news']
        avg_av_sentiment = sum(av_sentiments) / len(av_sentiments) if av_sentiments else None
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„
        keyword_sentiment = self.summarize_news_sentiment(unique_news)
        
        return {
            'ticker': ticker,
            'timestamp': datetime.now().isoformat(),
            'total_articles': len(unique_news),
            'articles': unique_news[:max_articles],
            'source_stats': source_stats,
            'sentiment_analysis': {
                'keyword_based': keyword_sentiment,
                'alphavantage_avg': avg_av_sentiment,
                'combined_score': (
                    (keyword_sentiment['score'] + avg_av_sentiment) / 2 
                    if avg_av_sentiment is not None 
                    else keyword_sentiment['score']
                )
            }
        }
    
    def _get_yahoo_market_news(self, max_articles: int = 10) -> List[Dict]:
        """Yahoo Finance ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news = []
        
        try:
            # SPY ETF ë‰´ìŠ¤ë¥¼ ì‹œì¥ ë‰´ìŠ¤ë¡œ ì‚¬ìš©
            spy = yf.Ticker("SPY")
            yf_news = spy.news
            
            for article in yf_news[:max_articles]:
                news.append({
                    'title': article.get('title', ''),
                    'summary': article.get('summary', ''),
                    'source': article.get('publisher', 'Yahoo Finance'),
                    'url': article.get('link', ''),
                    'published': datetime.fromtimestamp(
                        article.get('providerPublishTime', 0)
                    ).isoformat() if article.get('providerPublishTime') else '',
                    'type': 'market_news'
                })
        except Exception as e:
            print(f"Yahoo Finance ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news
    
    def _get_yahoo_economic_news(self, max_articles: int = 10) -> List[Dict]:
        """Yahoo Finance ê²½ì œ ë‰´ìŠ¤ (êµ­ì±„ ETF ë‰´ìŠ¤ í™œìš©)"""
        news = []
        
        try:
            # TLT (20ë…„ êµ­ì±„ ETF) ë‰´ìŠ¤ë¥¼ ê²½ì œ ë‰´ìŠ¤ë¡œ í™œìš©
            tlt = yf.Ticker("TLT")
            yf_news = tlt.news
            
            for article in yf_news[:max_articles]:
                news.append({
                    'title': article.get('title', ''),
                    'summary': article.get('summary', ''),
                    'source': article.get('publisher', 'Yahoo Finance'),
                    'url': article.get('link', ''),
                    'published': datetime.fromtimestamp(
                        article.get('providerPublishTime', 0)
                    ).isoformat() if article.get('providerPublishTime') else '',
                    'type': 'economic_news'
                })
        except Exception as e:
            print(f"Yahoo Finance ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news
    
    def summarize_news_sentiment(self, news_list: List[Dict]) -> Dict:
        """ë‰´ìŠ¤ ê°ì„± ìš”ì•½ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        if not news_list:
            return {"sentiment": "neutral", "score": 0, "article_count": 0}
        
        positive_keywords = [
            'surge', 'jump', 'rally', 'gain', 'rise', 'growth', 'bullish',
            'record high', 'beat', 'exceed', 'optimism', 'recovery', 'boom'
        ]
        negative_keywords = [
            'fall', 'drop', 'plunge', 'crash', 'decline', 'bearish', 'fear',
            'recession', 'crisis', 'miss', 'disappoint', 'concern', 'risk',
            'selloff', 'tumble', 'slump'
        ]
        
        positive_count = 0
        negative_count = 0
        
        for article in news_list:
            title = article.get('title', '') or ''
            summary = article.get('summary', '') or ''
            text = (title + ' ' + summary).lower()
            
            for keyword in positive_keywords:
                if keyword in text:
                    positive_count += 1
            
            for keyword in negative_keywords:
                if keyword in text:
                    negative_count += 1
        
        total = positive_count + negative_count
        if total == 0:
            score = 0
            sentiment = "neutral"
        else:
            score = (positive_count - negative_count) / total
            if score > 0.2:
                sentiment = "positive"
            elif score < -0.2:
                sentiment = "negative"
            else:
                sentiment = "neutral"
        
        return {
            "sentiment": sentiment,
            "score": round(score, 2),
            "positive_signals": positive_count,
            "negative_signals": negative_count,
            "article_count": len(news_list)
        }
    
    def get_news_summary(self) -> Dict:
        """ì „ì²´ ë‰´ìŠ¤ ìš”ì•½"""
        market_news = self.get_market_news(days=3, max_articles=15)
        economic_news = self.get_economic_news(days=3, max_articles=10)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "market_news": {
                "articles": market_news,
                "sentiment": self.summarize_news_sentiment(market_news)
            },
            "economic_news": {
                "articles": economic_news,
                "sentiment": self.summarize_news_sentiment(economic_news)
            }
        }


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    collector = NewsCollector()
    
    # API í‚¤ ìƒíƒœ í™•ì¸
    print("=" * 50)
    print("ğŸ“° ë‰´ìŠ¤ API ìƒíƒœ í™•ì¸")
    print("=" * 50)
    print(f"âœ… NewsAPI: {'ì„¤ì •ë¨' if collector.news_api_key else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"âœ… Alpha Vantage: {'ì„¤ì •ë¨' if collector.alpha_vantage_key else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"âœ… Finnhub: {'ì„¤ì •ë¨' if collector.finnhub_key else 'âŒ ë¯¸ì„¤ì • (ì„ íƒì )'}")
    print(f"âœ… Marketaux: {'ì„¤ì •ë¨' if collector.marketaux_key else 'âŒ ë¯¸ì„¤ì • (ì„ íƒì )'}")
    print()
    
    print("=== ì‹œì¥ ë‰´ìŠ¤ (ë‹¤ì¤‘ ì†ŒìŠ¤) ===")
    market_news = collector.get_market_news(max_articles=12)
    print(f"ì´ {len(market_news)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
    
    # ì†ŒìŠ¤ë³„ í†µê³„
    source_counts = {}
    for news in market_news:
        src = news.get('type', 'unknown')
        source_counts[src] = source_counts.get(src, 0) + 1
    print(f"ì†ŒìŠ¤ë³„ ìˆ˜ì§‘: {source_counts}")
    
    for news in market_news[:5]:
        source_type = news.get('type', 'unknown')
        sentiment = news.get('sentiment', {}).get('label', '')
        sentiment_str = f" [{sentiment}]" if sentiment else ""
        print(f"  [{source_type}]{sentiment_str} {news['title'][:50]}...")
    
    print("\n=== AAPL ì¢…í•© ë‰´ìŠ¤ ===")
    aapl_comprehensive = collector.get_comprehensive_stock_news("AAPL", max_articles=12)
    print(f"ì´ {aapl_comprehensive['total_articles']}ê°œ ê¸°ì‚¬")
    print(f"ì†ŒìŠ¤ë³„ ìˆ˜ì§‘: {aapl_comprehensive['source_stats']}")
    print(f"ê°ì„± ë¶„ì„: {aapl_comprehensive['sentiment_analysis']}")
    print("\nì£¼ìš” ê¸°ì‚¬:")
    for news in aapl_comprehensive['articles'][:3]:
        print(f"  - {news['title'][:60]}...")
    
    print("\n=== ë‰´ìŠ¤ ê°ì„± ìš”ì•½ ===")
    sentiment = collector.summarize_news_sentiment(market_news)
    print(f"í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„±: {sentiment['sentiment']}")
    print(f"ì ìˆ˜: {sentiment['score']}")
    print(f"ê¸ì • ì‹ í˜¸: {sentiment['positive_signals']}, ë¶€ì • ì‹ í˜¸: {sentiment['negative_signals']}")
